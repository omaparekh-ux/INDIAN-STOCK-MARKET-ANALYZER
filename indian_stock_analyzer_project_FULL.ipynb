{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2328000e",
   "metadata": {},
   "source": [
    "# Indian Stock Analyzer\n",
    "\n",
    "**AI‑Powered Market Trend & Stock Signal Platform (NSE / India)**\n",
    "\n",
    "This notebook is the **complete project report + runnable pipeline** for our *Indian Stock Analyzer*.\n",
    "It is structured exactly as required:\n",
    "\n",
    "1. **Problem Definition & Objective**  \n",
    "2. **Data Understanding & Preparation**  \n",
    "3. **Model / System Design**  \n",
    "4. **Core Implementation (runnable)**  \n",
    "5. **Evaluation & Analysis**  \n",
    "6. **Ethical Considerations & Responsible AI**  \n",
    "7. **Conclusion & Future Scope**\n",
    "\n",
    "> **Important:** The project supports **Live → Cache → Demo** fallback. If you don’t have API keys / internet, this notebook still runs using demo data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2871264",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "This section wires the local project code into the notebook runtime.\n",
    "\n",
    "Project root (from the submitted ZIP): `Indian Stock Analyzer/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Path + environment setup ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(r\"/mnt/data/isa/Indian Stock Analyzer\")\n",
    "assert PROJECT_ROOT.exists(), f\"Project root not found: {PROJECT_ROOT}\"\n",
    "\n",
    "# Add project to import path\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Load .env used by the Streamlit app (same behavior as app.py)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(dotenv_path=PROJECT_ROOT / \".env\", override=True)\n",
    "except Exception as e:\n",
    "    print(\"dotenv not available (ok).\", e)\n",
    "\n",
    "print(\"✅ Project root added:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Basic dependency checks (non-fatal) ---\n",
    "import importlib\n",
    "\n",
    "def check(pkg: str):\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Missing/failed import: {pkg} -> {e}\")\n",
    "        return False\n",
    "\n",
    "_ = [check(p) for p in [\"pandas\",\"numpy\",\"yfinance\",\"plotly\",\"requests\",\"sklearn\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa43cb9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1) Problem Definition & Objective\n",
    "\n",
    "### Selected Project Track\n",
    "**Track:** *AI/ML Decision Support System (Hybrid: Time‑Series + News + LLM + Risk/Optimization)*\n",
    "\n",
    "### Clear Problem Statement\n",
    "Indian retail investors and early traders typically rely on fragmented tools:\n",
    "- Separate apps for charts/indicators\n",
    "- Separate sites for news\n",
    "- Separate screeners for fundamentals\n",
    "- No consistent way to combine signals and **explain** “why this stock is ranked higher today”.\n",
    "\n",
    "**Problem:** Build a unified system that converts raw market + macro + news signals into **transparent, explainable rankings** and **risk-aware suggestions**.\n",
    "\n",
    "### Real‑World Relevance & Motivation\n",
    "- Indian markets are highly event-driven (results, RBI policy, geopolitics, commodity moves)\n",
    "- Retail users often overreact to noise; we need **signal fusion + guardrails**\n",
    "- APIs can fail / rate-limit. A reliable tool must handle outages (**cache/demo fallback**)\n",
    "\n",
    "### Primary Objectives\n",
    "- Compute multi-timeframe technical signals (RSI, MACD, SMA/EMA, volatility, breakouts)\n",
    "- Integrate **news bundles + sentiment** signals\n",
    "- Integrate **fundamentals & ownership/macro context** when available\n",
    "- Combine signals into an **explainable composite score** and verdict\n",
    "- Provide **forecast-style probability** (rise/fall/hold) with abstain thresholds\n",
    "- Provide **risk metrics + portfolio guardrails / sizing**\n",
    "- Keep the system robust using Live → Cache → Demo routing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b130f9b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2) Data Understanding & Preparation\n",
    "\n",
    "### Data Sources (as implemented in the codebase)\n",
    "Your project supports multiple providers through adapters and a router:\n",
    "\n",
    "**Price / OHLCV**\n",
    "- `analyzer/data_adapters/prices_yf.py` (Yahoo Finance)\n",
    "- `analyzer/data_adapters/alpha_vantage.py`\n",
    "- `analyzer/data_adapters/finnhub_adapter.py`\n",
    "- `analyzer/data_adapters/fmp_adapter.py`\n",
    "- `analyzer/data_adapters/prices_router.py` (provider routing + resilience)\n",
    "\n",
    "**Fundamentals**\n",
    "- `analyzer/data_adapters/fundamentals_yf.py`\n",
    "- `analyzer/data_adapters/fundamentals_providers.py`\n",
    "- `analyzer/features/fundamentals.py` + `fundamentals_pro_v2.py`\n",
    "\n",
    "**News & Sentiment**\n",
    "- `analyzer/data_adapters/news_providers.py` (news bundle)\n",
    "- `analyzer/features/news_sentiment.py`, `sentiment.py` (signal)\n",
    "\n",
    "**Macro & Vol Proxy**\n",
    "- `analyzer/data_adapters/macro_provider.py`\n",
    "- `analyzer/data_adapters/vol_proxy.py`\n",
    "\n",
    "**Universe**\n",
    "- `analyzer/data/nse_symbols.csv`\n",
    "\n",
    "### Preparation Strategy\n",
    "- Standardize symbol mapping to Yahoo tickers (e.g., `RELIANCE.NS`) using `analyzer/symbols`\n",
    "- Clean OHLCV time series (missing values, non-trading days)\n",
    "- Feature engineering:\n",
    "  - Returns, rolling volatility\n",
    "  - RSI / MACD / SMA/EMA\n",
    "  - Multi-timeframe alignment and confluence signals\n",
    "\n",
    "### Router & Reliability\n",
    "Provider routing is configured via:\n",
    "- `analyzer/config/router-spec.yaml`\n",
    "- `analyzer/config/runtime.yaml`\n",
    "\n",
    "The design supports:\n",
    "- **Live mode** when API/provider works\n",
    "- **Cache mode** when data already exists\n",
    "- **Demo mode** when providers are blocked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ea5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect the universe (NSE symbols) ---\n",
    "import pandas as pd\n",
    "\n",
    "universe_path = PROJECT_ROOT / \"analyzer\" / \"data\" / \"nse_symbols.csv\"\n",
    "universe = pd.read_csv(universe_path)\n",
    "print(\"Universe rows:\", len(universe))\n",
    "universe.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect router & runtime configuration (YAML) ---\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "router_spec_path = PROJECT_ROOT / \"analyzer\" / \"config\" / \"router-spec.yaml\"\n",
    "runtime_path = PROJECT_ROOT / \"analyzer\" / \"config\" / \"runtime.yaml\"\n",
    "\n",
    "router_spec = yaml.safe_load(router_spec_path.read_text(encoding=\"utf-8\"))\n",
    "runtime_cfg = yaml.safe_load(runtime_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "list(router_spec.keys()), list(runtime_cfg.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ed432",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3) Model / System Design\n",
    "\n",
    "### Technique Used (Hybrid AI System)\n",
    "This project is **not a single black‑box model**. It is a **hybrid pipeline**:\n",
    "\n",
    "- **Rule + indicator-based technical engine** (interpretable)\n",
    "- **ML/Calibration components** (optional, model artifacts can be plugged in)\n",
    "- **News/Sentiment scoring** (NLP sentiment)\n",
    "- **Probabilistic forecasting shim** (`predict_prob`) with regime-aware thresholds\n",
    "- **Risk & portfolio sizing layer** (guardrails, exposure limits, turnover)\n",
    "- **LLM Copilot (Big Bull 3.0)** for explanation / memo (local Ollama optional)\n",
    "\n",
    "### High-Level Architecture\n",
    "\n",
    "```\n",
    "User (Streamlit UI / Notebook)\n",
    "        |\n",
    "        v\n",
    "Symbol Resolver (NSE → Yahoo)\n",
    "        |\n",
    "        v\n",
    "Data Router (Live → Cache → Demo)\n",
    "  |      |        |\n",
    "  v      v        v\n",
    "Prices  Fundamentals  News/Macro\n",
    "  |         |           |\n",
    "  +---- Feature Engineering ----+\n",
    "               |\n",
    "               v\n",
    "TA Indicators + Strategy Engine + Sentiment\n",
    "               |\n",
    "               v\n",
    "Score Fusion (Technical + Fundamental + News)\n",
    "               |\n",
    "               v\n",
    "Forecast Probability + Risk Guardrails\n",
    "               |\n",
    "               v\n",
    "Rankings + Explainable Output (+ optional LLM memo)\n",
    "```\n",
    "\n",
    "### Justification of Design Choices\n",
    "- **Explainability:** indicators and feature-based scores are transparent\n",
    "- **Robustness:** router + cache + demo mode prevents total failure\n",
    "- **Safety:** risk guardrails and abstain thresholds prevent over-confidence\n",
    "- **Scalability:** adapters allow adding/removing providers without rewriting the UI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008e090",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4) Core Implementation (Runs Top-to-Bottom)\n",
    "\n",
    "We now run the core pipeline for a small watchlist.\n",
    "You can change the `symbols` list to any NSE tickers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354066fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Choose symbols to analyze ---\n",
    "# Use Yahoo-format ('.NS') OR normal names (we will resolve)\n",
    "symbols = [\"RELIANCE\", \"TCS\", \"INFY\", \"HDFCBANK\", \"SBIN\"]\n",
    "\n",
    "from analyzer.symbols import resolve_to_yahoo\n",
    "resolved = [resolve_to_yahoo(s) for s in symbols]\n",
    "resolved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ad374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fetch price history (resilient) OR generate demo series ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from analyzer.data_adapters.prices_yf import get_price_history_resilient\n",
    "\n",
    "\n",
    "def demo_ohlcv(n=260, start=100.0, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rets = rng.normal(0.0005, 0.02, size=n)\n",
    "    px = start * np.exp(np.cumsum(rets))\n",
    "    idx = pd.bdate_range(end=pd.Timestamp.today().normalize(), periods=n)\n",
    "    df = pd.DataFrame({\n",
    "        \"Open\": px * (1 + rng.normal(0, 0.003, size=n)),\n",
    "        \"High\": px * (1 + rng.normal(0.01, 0.004, size=n)),\n",
    "        \"Low\":  px * (1 - rng.normal(0.01, 0.004, size=n)),\n",
    "        \"Close\": px,\n",
    "        \"Volume\": rng.integers(2e6, 15e6, size=n)\n",
    "    }, index=idx)\n",
    "    return df\n",
    "\n",
    "prices = {}\n",
    "for sym in resolved:\n",
    "    try:\n",
    "        df = get_price_history_resilient(sym, period=\"1y\", interval=\"1d\")\n",
    "        if df is None or getattr(df, \"empty\", True):\n",
    "            raise ValueError(\"empty\")\n",
    "        prices[sym] = df\n",
    "    except Exception:\n",
    "        prices[sym] = demo_ohlcv(seed=abs(hash(sym)) % (2**32))\n",
    "\n",
    "{sym: prices[sym].shape for sym in prices}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f669cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute Technical Indicators (RSI, MACD, SMA/EMA, etc.) ---\n",
    "from analyzer.ta.indicators import compute_all_indicators\n",
    "\n",
    "indicators = {sym: compute_all_indicators(df) for sym, df in prices.items()}\n",
    "\n",
    "# show one\n",
    "sample_sym = resolved[0]\n",
    "indicators[sample_sym].tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e80c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute key Technical Signals used in the app ---\n",
    "from analyzer.ta.signals import (\n",
    "    mtf_alignment_signal,\n",
    "    hybrid_confluence_signal,\n",
    "    ema200_macd_signal,\n",
    "    atr_breakout_signal,\n",
    "    bollinger_volume_signal,\n",
    "    macd_hist_contraction_signal,\n",
    ")\n",
    "\n",
    "def signal_pack(df_ind):\n",
    "    return {\n",
    "        \"mtf_alignment\": mtf_alignment_signal(df_ind),\n",
    "        \"hybrid_confluence\": hybrid_confluence_signal(df_ind),\n",
    "        \"ema200_macd\": ema200_macd_signal(df_ind),\n",
    "        \"atr_breakout\": atr_breakout_signal(df_ind),\n",
    "        \"bollinger_volume\": bollinger_volume_signal(df_ind),\n",
    "        \"macd_hist_contraction\": macd_hist_contraction_signal(df_ind),\n",
    "    }\n",
    "\n",
    "signals = {sym: signal_pack(indicators[sym]) for sym in resolved}\n",
    "signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88076501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strategy Engine (100 strategies) + prediction projection helpers ---\n",
    "from analyzer.ta.strategy_engine import run_strategies\n",
    "from analyzer.ta.projections import overall_predicted_pct, tally_strategy_buckets\n",
    "\n",
    "strategy_rows = {}\n",
    "for sym in resolved:\n",
    "    rows = run_strategies(indicators[sym])\n",
    "    strategy_rows[sym] = rows\n",
    "\n",
    "# Quick bucket counts per symbol\n",
    "bucket_counts = {sym: tally_strategy_buckets(strategy_rows[sym]) for sym in resolved}\n",
    "bucket_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3243ad",
   "metadata": {},
   "source": [
    "### Fundamentals + News/Sentiment (Hybrid Signals)\n",
    "The Streamlit app uses:\n",
    "- `get_fundamentals_snapshot` + `compute_fundamentals`\n",
    "- `get_news_bundle` + `get_sentiment_signal`\n",
    "\n",
    "All calls are guarded (if blocked, we still proceed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0129acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fundamentals snapshot + computed fundamentals ---\n",
    "from analyzer.data_adapters.prices_yf import get_fundamentals_snapshot\n",
    "from analyzer.features.fundamentals import compute_fundamentals\n",
    "\n",
    "fund_snap = {}\n",
    "fund_comp = {}\n",
    "for sym in resolved:\n",
    "    try:\n",
    "        snap = get_fundamentals_snapshot(sym)\n",
    "    except Exception:\n",
    "        snap = {}\n",
    "    fund_snap[sym] = snap\n",
    "\n",
    "    try:\n",
    "        fund_comp[sym] = compute_fundamentals(snap)\n",
    "    except Exception:\n",
    "        fund_comp[sym] = {}\n",
    "\n",
    "# show one\n",
    "sym = resolved[0]\n",
    "fund_snap[sym], list(fund_comp[sym].keys())[:12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b920cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- News bundle + daily sentiment signal ---\n",
    "from analyzer.data_adapters.news_providers import get_news_bundle\n",
    "from analyzer.features.sentiment import get_sentiment_signal\n",
    "\n",
    "news = {}\n",
    "sent = {}\n",
    "for sym in resolved:\n",
    "    try:\n",
    "        news[sym] = get_news_bundle(sym, max_items=12)\n",
    "    except Exception:\n",
    "        news[sym] = {\"items\": [], \"source\": \"unavailable\"}\n",
    "\n",
    "    try:\n",
    "        sent[sym] = get_sentiment_signal(sym, news_bundle=news[sym])\n",
    "    except Exception:\n",
    "        sent[sym] = {\"sentiment\": 0.0, \"confidence\": 0.0, \"note\": \"unavailable\"}\n",
    "\n",
    "# show one\n",
    "resolved[0], sent[resolved[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f568f9a8",
   "metadata": {},
   "source": [
    "### Unified Investability Score (Explainable Fusion)\n",
    "The app fuses **technical + fundamental + news** to compute a final decision.\n",
    "\n",
    "Key functions:\n",
    "- `analyzer/decision/investability.py` → `combine_scores`, `investability`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9144a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Combine scores + investability verdict ---\n",
    "from analyzer.decision.investability import combine_scores, investability\n",
    "\n",
    "combined = {}\n",
    "for sym in resolved:\n",
    "    try:\n",
    "        # combine_scores expects (ta, fa, news) style objects; our pipeline uses indicators + fundamentals + sentiment\n",
    "        combined[sym] = combine_scores(\n",
    "            technical=signals[sym],\n",
    "            fundamentals=fund_comp[sym],\n",
    "            sentiment=sent[sym],\n",
    "        )\n",
    "    except Exception as e:\n",
    "        combined[sym] = {\"error\": str(e)}\n",
    "\n",
    "verdicts = {}\n",
    "for sym in resolved:\n",
    "    try:\n",
    "        verdicts[sym] = investability(combined[sym])\n",
    "    except Exception as e:\n",
    "        verdicts[sym] = {\"error\": str(e)}\n",
    "\n",
    "verdicts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b54f4c",
   "metadata": {},
   "source": [
    "### Forecast Probability (Regime-aware)\n",
    "The project exposes a stable API `predict_prob` which:\n",
    "- prefers the modern BigBull pipeline if present\n",
    "- falls back to ensemble or heuristic\n",
    "- uses regime/horizon thresholds and can abstain\n",
    "\n",
    "File: `analyzer/forecast/prob_predictor.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75bb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Forecast-style probability payload ---\n",
    "from analyzer.forecast.prob_predictor import predict_prob\n",
    "\n",
    "prob_payload = {}\n",
    "for sym in resolved:\n",
    "    try:\n",
    "        df = prices[sym]\n",
    "        prob_payload[sym] = predict_prob(\n",
    "            df=df,\n",
    "            fundamentals_info=fund_snap.get(sym),\n",
    "            news_bundle=news.get(sym),\n",
    "            horizon_key=\"20D\",\n",
    "            models_dir=str(PROJECT_ROOT / \"models\")\n",
    "        )\n",
    "    except Exception as e:\n",
    "        prob_payload[sym] = {\"error\": str(e)}\n",
    "\n",
    "# show\n",
    "prob_payload[resolved[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559007bd",
   "metadata": {},
   "source": [
    "### Ranking (Stocks → Ordered list)\n",
    "We build a simple ranking using the probability + confidence and investability output.\n",
    "This is **explainable** (we can show each component).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build an explainable ranking table ---\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for sym in resolved:\n",
    "    p = prob_payload.get(sym, {})\n",
    "    inv = verdicts.get(sym, {})\n",
    "    rows.append({\n",
    "        \"symbol\": sym,\n",
    "        \"verdict\": p.get(\"verdict\", \"NA\"),\n",
    "        \"p_up\": p.get(\"p_up\", None),\n",
    "        \"confidence_pct\": p.get(\"confidence_pct\", None),\n",
    "        \"expected_return\": p.get(\"expected_return\", None),\n",
    "        \"abstain\": p.get(\"abstain\", None),\n",
    "        \"investability\": inv.get(\"verdict\") if isinstance(inv, dict) else str(inv),\n",
    "        \"notes\": (p.get(\"details\", {}) or {}).get(\"source\")\n",
    "    })\n",
    "\n",
    "rank_df = pd.DataFrame(rows)\n",
    "rank_df[\"rank_score\"] = (\n",
    "    rank_df[\"p_up\"].fillna(0.5) * (rank_df[\"confidence_pct\"].fillna(0) / 100.0)\n",
    ")\n",
    "rank_df = rank_df.sort_values(\"rank_score\", ascending=False)\n",
    "rank_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb0195",
   "metadata": {},
   "source": [
    "### Risk & Portfolio Optimization\n",
    "The project includes risk sizing and guardrails. The same logic used in backtesting can\n",
    "translate signal tables into **portfolio weights**.\n",
    "\n",
    "Files:\n",
    "- `analyzer/modeling/position_sizing.py`\n",
    "- `analyzer/backtest/positioning.py` (weights_from_signals)\n",
    "- `analyzer/ui/tabs/portfolio_risk.py` (Streamlit tab wrapper)\n",
    "\n",
    "Below we demonstrate building a tiny weights panel from probability payloads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6aa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build a minimal long-form signals table for weights_from_signals ---\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from analyzer.modeling.position_sizing import PositionSizingConfig\n",
    "from analyzer.backtest.positioning import weights_from_signals, PortfolioGuardrails\n",
    "\n",
    "# Create a one-timestamp signal snapshot.\n",
    "# If your quantile models exist, use predict_quantiles_for_frame outputs instead.\n",
    "now = pd.Timestamp.utcnow().normalize()\n",
    "\n",
    "sig_rows = []\n",
    "for sym in resolved:\n",
    "    p = prob_payload.get(sym, {})\n",
    "    # use conservative interval placeholders if quantiles not available\n",
    "    med = float(p.get(\"expected_return\", 0.0) or 0.0)\n",
    "    sig_rows.append({\n",
    "        \"timestamp\": now,\n",
    "        \"symbol\": sym,\n",
    "        \"median\": med,\n",
    "        \"low\": med - 0.03,\n",
    "        \"high\": med + 0.03,\n",
    "        \"p_up\": float(p.get(\"p_up\", 0.5) or 0.5),\n",
    "        \"atr_pct\": 0.02,\n",
    "    })\n",
    "\n",
    "signals_long = pd.DataFrame(sig_rows)\n",
    "\n",
    "cfg = PositionSizingConfig(\n",
    "    max_single_weight=0.20,\n",
    "    min_p_up=0.55,\n",
    "    min_confidence_pct=60.0,\n",
    ")\n",
    "guards = PortfolioGuardrails(max_gross_exposure=1.0, max_single_weight=0.20, max_turnover_per_step=None)\n",
    "\n",
    "w = weights_from_signals(signals_long, cfg, guards)\n",
    "w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ec9c6",
   "metadata": {},
   "source": [
    "### Backtesting (User Backtest Engine)\n",
    "The project includes a backtesting engine:\n",
    "- `analyzer/backtest/engine.py` + `simple_engine.py` + `walkforward.py`\n",
    "\n",
    "We demonstrate a safe call. If backtest parameters mismatch, the cell will not crash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fcb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run a small backtest (guarded) ---\n",
    "from analyzer.backtest.engine import run_user_backtest, BacktestError\n",
    "\n",
    "bt_out = {}\n",
    "for sym in resolved[:2]:\n",
    "    try:\n",
    "        res = run_user_backtest(\n",
    "            symbol=sym,\n",
    "            period=\"1y\",\n",
    "            interval=\"1d\",\n",
    "            strategy_name=\"EMA200_MACD\",  # one of the strategies used in the app\n",
    "            initial_cash=100000,\n",
    "            slippage_bps=5,\n",
    "            fee_bps=2,\n",
    "        )\n",
    "        bt_out[sym] = {\n",
    "            \"final_equity\": res.get(\"final_equity\"),\n",
    "            \"cagr\": res.get(\"cagr\"),\n",
    "            \"sharpe\": res.get(\"sharpe\"),\n",
    "            \"max_drawdown\": res.get(\"max_drawdown\"),\n",
    "            \"trades\": res.get(\"trades\"),\n",
    "        }\n",
    "    except BacktestError as e:\n",
    "        bt_out[sym] = {\"error\": f\"BacktestError: {e}\"}\n",
    "    except Exception as e:\n",
    "        bt_out[sym] = {\"error\": str(e)}\n",
    "\n",
    "bt_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126baff6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5) Evaluation & Analysis\n",
    "\n",
    "### Metrics Used\n",
    "Your project uses/mentions multiple evaluation views depending on the module:\n",
    "\n",
    "**Technical / Strategy evaluation**\n",
    "- win rate, hit rate\n",
    "- Sharpe ratio\n",
    "- max drawdown\n",
    "- CAGR / total return\n",
    "- trade count, average trade return\n",
    "\n",
    "**Forecast evaluation**\n",
    "- calibrated confidence (bucket-based)\n",
    "- abstain rate vs precision target\n",
    "- horizon-based thresholding\n",
    "\n",
    "**System reliability**\n",
    "- cache hit rate\n",
    "- fallback usage (demo mode)\n",
    "- provider health diagnostics\n",
    "\n",
    "### Sample Outputs\n",
    "- Ranking table (above)\n",
    "- Probability payload with `p_up`, `confidence_pct`, `expected_return`\n",
    "- Optional LLM memo via Big Bull 3.0 (Ollama)\n",
    "\n",
    "### Limitations\n",
    "- Market regime shifts can break indicator relationships\n",
    "- News sentiment is noisy and may lag actual price moves\n",
    "- Live APIs can rate-limit; system must rely on cache\n",
    "- Forecast artifacts may be absent (models/ empty) → fallback heuristics used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcfb7eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6) Ethical Considerations & Responsible AI\n",
    "\n",
    "### Bias & Fairness\n",
    "- The system may implicitly favor large-cap, liquid stocks due to better data coverage.\n",
    "- News coverage is uneven: popular stocks get more headlines.\n",
    "\n",
    "### Dataset Limitations\n",
    "- Yahoo/API data can contain missing candles or adjusted series changes.\n",
    "- Fundamentals from free sources may be delayed.\n",
    "\n",
    "### Responsible Use\n",
    "- This is a **decision-support** tool, not guaranteed prediction.\n",
    "- Outputs should be used with risk management and personal judgement.\n",
    "- Always disclose that predictions are probabilistic and can be wrong.\n",
    "\n",
    "### Safety Features Included\n",
    "- Abstain thresholds (don’t force a trade)\n",
    "- Confidence calibration buckets (when enabled)\n",
    "- Portfolio guardrails (gross exposure, max single weight, turnover caps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb84ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7) Conclusion & Future Scope\n",
    "\n",
    "### Summary\n",
    "We built a **unified Indian Stock Analyzer** that:\n",
    "- Pulls market data via a resilient router\n",
    "- Computes multi-indicator technical analysis\n",
    "- Integrates fundamentals + news sentiment\n",
    "- Produces explainable rankings and probability outputs\n",
    "- Includes backtesting and risk guardrails\n",
    "- Remains reliable using cache/demo fallbacks\n",
    "\n",
    "### Future Enhancements\n",
    "- Add official NSE/BSE corporate actions + better adjustments\n",
    "- Improve sentiment with transformer-based finance NLP\n",
    "- Add sector-neutral ranking and factor exposure control\n",
    "- Train & bundle horizon-specific models (quantiles + classifier) in `models/`\n",
    "- Automate scheduled EOD caching (for faster UI + no API rate-limit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21972e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: LLM Copilot (Big Bull 3.0) — Prompt Engineering\n",
    "\n",
    "The project includes a local LLM agent (`analyzer/agents/bigbull_agent.py`) that:\n",
    "- builds a structured context bundle (`context_bus.py`)\n",
    "- queries Ollama with a persona model tag\n",
    "- verifies JSON output (`verifier.py`)\n",
    "- optionally calibrates confidence buckets\n",
    "\n",
    "If Ollama is available locally, you can call it like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: Big Bull 3.0 local memo (requires Ollama running) ---\n",
    "try:\n",
    "    from analyzer.agents.bigbull_agent import query_bigbull\n",
    "    # Note: We pass cached/demo prices to avoid live fetch.\n",
    "    sym = resolved[0]\n",
    "    out = query_bigbull(\n",
    "        symbol=sym,\n",
    "        prices=prices[sym],\n",
    "        indicators=indicators[sym],\n",
    "        fundamentals=fund_snap.get(sym),\n",
    "        news=news.get(sym),\n",
    "        extra_prompt=\"Give a concise trading/investing memo with risks and invalidation levels.\"\n",
    "    )\n",
    "    out.keys(), str(out.get(\"memo\", \"\"))[:500]\n",
    "except Exception as e:\n",
    "    print(\"LLM copilot not available in this environment:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
